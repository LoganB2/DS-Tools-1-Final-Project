# DS-Tools-1-Final-Project
A project combining web scraping, data processing, data cleaning, data visualization, feature engineering, NLP, and predictive modeling.

In this project, Aaron Brommers and I use web scraping to gather text data from wikipedia. We collect all the text from roughly 100,000 wikipedia articles and store the text as indivual sentences that we clean, process, visualize and eventually use to create a predictive language model. 
